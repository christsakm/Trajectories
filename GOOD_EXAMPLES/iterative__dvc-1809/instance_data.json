{
    "instance_id": "iterative__dvc-1809",
    "hints_text": "",
    "patch": "diff --git a/dvc/command/metrics.py b/dvc/command/metrics.py\n--- a/dvc/command/metrics.py\n+++ b/dvc/command/metrics.py\n@@ -107,7 +107,13 @@ def add_parser(subparsers, parent_parser):\n         \"path\", nargs=\"?\", help=\"Path to a metric file or a directory.\"\n     )\n     metrics_show_parser.add_argument(\n-        \"-t\", \"--type\", help=\"Type of metrics (raw/json/tsv/htsv/csv/hcsv).\"\n+        \"-t\",\n+        \"--type\",\n+        help=(\n+            \"Type of metrics (json/tsv/htsv/csv/hcsv). \"\n+            \"It can be detected by the file extension automatically. \"\n+            \"Unsupported types will be treated as raw.\"\n+        ),\n     )\n     metrics_show_parser.add_argument(\n         \"-x\", \"--xpath\", help=\"json/tsv/htsv/csv/hcsv path.\"\ndiff --git a/dvc/repo/metrics/show.py b/dvc/repo/metrics/show.py\n--- a/dvc/repo/metrics/show.py\n+++ b/dvc/repo/metrics/show.py\n@@ -129,6 +129,8 @@ def _read_metrics(self, metrics, branch):\n     res = {}\n     for out, typ, xpath in metrics:\n         assert out.scheme == \"local\"\n+        if not typ:\n+            typ = os.path.splitext(out.path.lower())[1].replace(\".\", \"\")\n         if out.use_cache:\n             metric = _read_metrics_filesystem(\n                 self.cache.local.get(out.checksum),\n",
    "test_patch": "diff --git a/tests/test_metrics.py b/tests/test_metrics.py\n--- a/tests/test_metrics.py\n+++ b/tests/test_metrics.py\n@@ -541,3 +541,58 @@ def test_add(self):\n \n     def test_run(self):\n         self._test_metrics(self._do_run)\n+\n+\n+class TestMetricsType(TestDvc):\n+    branches = [\"foo\", \"bar\", \"baz\"]\n+    files = [\n+        \"metric\",\n+        \"metric.txt\",\n+        \"metric.json\",\n+        \"metric.tsv\",\n+        \"metric.htsv\",\n+        \"metric.csv\",\n+        \"metric.hcsv\",\n+    ]\n+    xpaths = [None, None, \"branch\", \"0,0\", \"0,branch\", \"0,0\", \"0,branch\"]\n+\n+    def setUp(self):\n+        super(TestMetricsType, self).setUp()\n+        self.dvc.scm.commit(\"init\")\n+\n+        for branch in self.branches:\n+            self.dvc.scm.checkout(branch, create_new=True)\n+            with open(\"metric\", \"w+\") as fd:\n+                fd.write(branch)\n+            with open(\"metric.txt\", \"w+\") as fd:\n+                fd.write(branch)\n+            with open(\"metric.json\", \"w+\") as fd:\n+                json.dump({\"branch\": branch}, fd)\n+            with open(\"metric.csv\", \"w+\") as fd:\n+                fd.write(branch)\n+            with open(\"metric.hcsv\", \"w+\") as fd:\n+                fd.write(\"branch\\n\")\n+                fd.write(branch)\n+            with open(\"metric.tsv\", \"w+\") as fd:\n+                fd.write(branch)\n+            with open(\"metric.htsv\", \"w+\") as fd:\n+                fd.write(\"branch\\n\")\n+                fd.write(branch)\n+            self.dvc.run(metrics_no_cache=self.files, overwrite=True)\n+            self.dvc.scm.add(self.files + [\"metric.dvc\"])\n+            self.dvc.scm.commit(\"metric\")\n+\n+        self.dvc.scm.checkout(\"master\")\n+\n+    def test_show(self):\n+        for file_name, xpath in zip(self.files, self.xpaths):\n+            self._do_show(file_name, xpath)\n+\n+    def _do_show(self, file_name, xpath):\n+        ret = self.dvc.metrics.show(file_name, xpath=xpath, all_branches=True)\n+        self.assertEqual(len(ret), 3)\n+        for branch in self.branches:\n+            if isinstance(ret[branch][file_name], list):\n+                self.assertSequenceEqual(ret[branch][file_name], [branch])\n+            else:\n+                self.assertSequenceEqual(ret[branch][file_name], branch)\n",
    "created_at": "2019-03-30T11:47:50Z",
    "problem_statement": "metrics: automatic type detection\nE.g. if we see that output has `.json` suffix, we could safely assume that it is `--type json` without explicitly specifying it.\n",
    "repo": "iterative/dvc",
    "base_commit": "b3addbd2832ffda1a4ec9a9ac3958ed9a43437dd",
    "version": "0.33",
    "PASS_TO_PASS": [
        "tests/test_metrics.py::TestNoMetrics::test_cli",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_is_none",
        "tests/test_metrics.py::TestMetricsRecursive::test",
        "tests/test_metrics.py::TestMetricsCLI::test_binary",
        "tests/test_metrics.py::TestMetricsReproCLI::test_dir",
        "tests/test_metrics.py::TestMetrics::test_xpath_is_none",
        "tests/test_metrics.py::TestMetrics::test_show",
        "tests/test_metrics.py::TestMetricsCLI::test_wrong_type_add",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_all_with_header",
        "tests/test_metrics.py::TestMetricsReproCLI::test_binary",
        "tests/test_metrics.py::TestNoMetrics::test",
        "tests/test_metrics.py::TestMetricsCLI::test_formatted_output",
        "tests/test_metrics.py::TestMetricsCLI::test_show",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_all",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_all_rows",
        "tests/test_metrics.py::TestMetrics::test_xpath_is_empty",
        "tests/test_metrics.py::TestMetrics::test_xpath_all_columns",
        "tests/test_metrics.py::TestMetrics::test_formatted_output",
        "tests/test_metrics.py::TestMetricsCLI::test_unknown_type_ignored",
        "tests/test_metrics.py::TestMetrics::test_xpath_all",
        "tests/test_metrics.py::TestMetrics::test_unknown_type_ignored",
        "tests/test_metrics.py::TestMetricsReproCLI::test",
        "tests/test_metrics.py::TestCachedMetrics::test_add",
        "tests/test_metrics.py::TestMetrics::test_xpath_all_rows",
        "tests/test_metrics.py::TestMetrics::test_xpath_all_with_header",
        "tests/test_metrics.py::TestCachedMetrics::test_run",
        "tests/test_metrics.py::TestMetrics::test_type_case_normalized",
        "tests/test_metrics.py::TestMetricsCLI::test_wrong_type_show",
        "tests/test_metrics.py::TestMetricsCLI::test_type_case_normalized",
        "tests/test_metrics.py::TestMetricsCLI::test_dir",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_is_empty",
        "tests/test_metrics.py::TestMetricsCLI::test_wrong_type_modify",
        "tests/test_metrics.py::TestMetricsCLI::test",
        "tests/test_metrics.py::TestMetricsCLI::test_non_existing",
        "tests/test_metrics.py::TestMetricsCLI::test_xpath_all_columns"
    ],
    "FAIL_TO_PASS": [
        "tests/test_metrics.py::TestMetricsType::test_show"
    ]
}