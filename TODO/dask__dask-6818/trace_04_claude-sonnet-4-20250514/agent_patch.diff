diff --git a/dask/dataframe/io/csv.py b/dask/dataframe/io/csv.py
index 6b34c09fb..80972b22e 100644
--- a/dask/dataframe/io/csv.py
+++ b/dask/dataframe/io/csv.py
@@ -318,6 +318,7 @@ def text_blocks_to_pandas(
     enforce=False,
     specified_dtypes=None,
     path=None,
+    blocksize=None,
 ):
     """Convert blocks of bytes to a dask.dataframe
 
@@ -380,7 +381,7 @@ def text_blocks_to_pandas(
     # Create mask of first blocks from nested block_lists
     is_first = tuple(block_mask(block_lists))
 
-    name = "read-csv-" + tokenize(reader, columns, enforce, head)
+    name = "read-csv-" + tokenize(reader, columns, enforce, head, blocksize)
 
     if path:
         block_file_names = [basename(b[1].path) for b in blocks]
@@ -604,6 +605,7 @@ def read_pandas(
         enforce=enforce,
         specified_dtypes=specified_dtypes,
         path=path,
+        blocksize=blocksize,
     )
 
 
diff --git a/dask/dataframe/io/tests/test_csv.py b/dask/dataframe/io/tests/test_csv.py
index 75045e51e..ffccf838c 100644
--- a/dask/dataframe/io/tests/test_csv.py
+++ b/dask/dataframe/io/tests/test_csv.py
@@ -182,11 +182,11 @@ def test_text_blocks_to_pandas_simple(reader, files):
     head = pandas_read_text(reader, files["2014-01-01.csv"], b"", {})
     header = files["2014-01-01.csv"].split(b"\n")[0] + b"\n"
 
-    df = text_blocks_to_pandas(reader, blocks, header, head, kwargs)
+    df = text_blocks_to_pandas(reader, blocks, header, head, kwargs, blocksize=None)
     assert isinstance(df, dd.DataFrame)
     assert list(df.columns) == ["name", "amount", "id"]
 
-    values = text_blocks_to_pandas(reader, blocks, header, head, kwargs)
+    values = text_blocks_to_pandas(reader, blocks, header, head, kwargs, blocksize=None)
     assert isinstance(values, dd.DataFrame)
     assert hasattr(values, "dask")
     assert len(values.dask) == 3
@@ -202,7 +202,7 @@ def test_text_blocks_to_pandas_kwargs(reader, files):
     head = pandas_read_text(reader, files["2014-01-01.csv"], b"", kwargs)
     header = files["2014-01-01.csv"].split(b"\n")[0] + b"\n"
 
-    df = text_blocks_to_pandas(reader, blocks, header, head, kwargs)
+    df = text_blocks_to_pandas(reader, blocks, header, head, kwargs, blocksize=None)
     assert list(df.columns) == ["name", "id"]
     result = df.compute()
     assert (result.columns == df.columns).all()
@@ -217,7 +217,7 @@ def test_text_blocks_to_pandas_blocked(reader, files):
         lines = b.split(b"\n")
         blocks.append([b"\n".join(bs) for bs in partition_all(2, lines)])
 
-    df = text_blocks_to_pandas(reader, blocks, header, expected.head(), {})
+    df = text_blocks_to_pandas(reader, blocks, header, expected.head(), {}, blocksize=None)
     assert_eq(
         df.compute().reset_index(drop=True),
         expected.reset_index(drop=True),
@@ -226,7 +226,7 @@ def test_text_blocks_to_pandas_blocked(reader, files):
 
     expected2 = expected[["name", "id"]]
     df = text_blocks_to_pandas(
-        reader, blocks, header, expected2.head(), {"usecols": ["name", "id"]}
+        reader, blocks, header, expected2.head(), {"usecols": ["name", "id"]}, blocksize=None
     )
     assert_eq(
         df.compute().reset_index(drop=True),
@@ -287,7 +287,7 @@ tsv_blocks = [
 def test_enforce_dtypes(reader, blocks):
     head = reader(BytesIO(blocks[0][0]), header=0)
     header = blocks[0][0].split(b"\n")[0] + b"\n"
-    dfs = text_blocks_to_pandas(reader, blocks, header, head, {})
+    dfs = text_blocks_to_pandas(reader, blocks, header, head, {}, blocksize=None)
     dfs = dask.compute(dfs, scheduler="sync")
     assert all(df.dtypes.to_dict() == head.dtypes.to_dict() for df in dfs)
 
@@ -302,7 +302,7 @@ def test_enforce_columns(reader, blocks):
     head = reader(BytesIO(blocks[0][0]), header=0)
     header = blocks[0][0].split(b"\n")[0] + b"\n"
     with pytest.raises(ValueError):
-        dfs = text_blocks_to_pandas(reader, blocks, header, head, {}, enforce=True)
+        dfs = text_blocks_to_pandas(reader, blocks, header, head, {}, enforce=True, blocksize=None)
         dask.compute(*dfs, scheduler="sync")
 
 
