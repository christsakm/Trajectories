diff --git a/monai/losses/dice.py b/monai/losses/dice.py
index 869dd05a..715c6714 100644
--- a/monai/losses/dice.py
+++ b/monai/losses/dice.py
@@ -803,6 +803,8 @@ class DiceFocalLoss(_Loss):
         """
         super().__init__()
         self.dice = DiceLoss(
+            include_background=include_background,
+            to_onehot_y=to_onehot_y,
             sigmoid=sigmoid,
             softmax=softmax,
             other_act=other_act,
@@ -813,15 +815,19 @@ class DiceFocalLoss(_Loss):
             smooth_dr=smooth_dr,
             batch=batch,
         )
-        self.focal = FocalLoss(gamma=gamma, weight=focal_weight, reduction=reduction)
+        self.focal = FocalLoss(
+            include_background=include_background,
+            to_onehot_y=to_onehot_y,
+            gamma=gamma,
+            weight=focal_weight,
+            reduction=reduction,
+        )
         if lambda_dice < 0.0:
             raise ValueError("lambda_dice should be no less than 0.0.")
         if lambda_focal < 0.0:
             raise ValueError("lambda_focal should be no less than 0.0.")
         self.lambda_dice = lambda_dice
         self.lambda_focal = lambda_focal
-        self.to_onehot_y = to_onehot_y
-        self.include_background = include_background
 
     def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
         """
@@ -838,22 +844,7 @@ class DiceFocalLoss(_Loss):
         if len(input.shape) != len(target.shape):
             raise ValueError("the number of dimensions for input and target should be the same.")
 
-        n_pred_ch = input.shape[1]
-
-        if self.to_onehot_y:
-            if n_pred_ch == 1:
-                warnings.warn("single channel prediction, `to_onehot_y=True` ignored.")
-            else:
-                target = one_hot(target, num_classes=n_pred_ch)
-
-        if not self.include_background:
-            if n_pred_ch == 1:
-                warnings.warn("single channel prediction, `include_background=False` ignored.")
-            else:
-                # if skipping background, removing first channel
-                target = target[:, 1:]
-                input = input[:, 1:]
-
+        # Delegate preprocessing (one-hot, background channel handling, activation) to the composed losses
         dice_loss = self.dice(input, target)
         focal_loss = self.focal(input, target)
         total_loss: torch.Tensor = self.lambda_dice * dice_loss + self.lambda_focal * focal_loss
diff --git a/repro.py b/repro.py
new file mode 100644
index 00000000..f12e1643
--- /dev/null
+++ b/repro.py
@@ -0,0 +1,13 @@
+import torch
+from monai.losses import DiceFocalLoss
+from monai.networks import one_hot
+
+
+tx = torch.rand(1, 2, 64, 64)  # logits
+# generate random binary labels and one-hot encode to 2 classes
+label_idx = (torch.rand(1, 1, 64, 64) > 0.5).long()
+ty = one_hot(label_idx, 2)
+
+loss = DiceFocalLoss(include_background=False, softmax=True)
+print('compute loss...')
+print(loss(tx, ty))
