diff --git a/monai/losses/dice.py b/monai/losses/dice.py
index 869dd05a..bbadfee9 100644
--- a/monai/losses/dice.py
+++ b/monai/losses/dice.py
@@ -130,14 +130,9 @@ class DiceLoss(_Loss):
             input = torch.sigmoid(input)
 
         n_pred_ch = input.shape[1]
-        if self.softmax:
-            if n_pred_ch == 1:
-                warnings.warn("single channel prediction, `softmax=True` ignored.")
-            else:
-                input = torch.softmax(input, 1)
-
-        if self.other_act is not None:
-            input = self.other_act(input)
+        
+        # Store original number of channels for background exclusion check
+        orig_n_pred_ch = n_pred_ch
 
         if self.to_onehot_y:
             if n_pred_ch == 1:
@@ -146,12 +141,24 @@ class DiceLoss(_Loss):
                 target = one_hot(target, num_classes=n_pred_ch)
 
         if not self.include_background:
-            if n_pred_ch == 1:
+            if orig_n_pred_ch == 1:
                 warnings.warn("single channel prediction, `include_background=False` ignored.")
             else:
                 # if skipping background, removing first channel
                 target = target[:, 1:]
                 input = input[:, 1:]
+                # Update n_pred_ch after removing background
+                n_pred_ch = input.shape[1]
+
+        # Get class probabilities from logits
+        if self.softmax:
+            if n_pred_ch == 1:
+                warnings.warn("single channel prediction, `softmax=True` ignored.")
+            else:
+                input = torch.softmax(input, 1)
+
+        if self.other_act is not None:
+            input = self.other_act(input)
 
         if target.shape != input.shape:
             raise AssertionError(f"ground truth has different shape ({target.shape}) from input ({input.shape})")
@@ -846,6 +853,14 @@ class DiceFocalLoss(_Loss):
             else:
                 target = one_hot(target, num_classes=n_pred_ch)
 
+        # Store original input for focal loss
+        focal_input = input
+        focal_target = target
+
+        # Apply softmax to input before background exclusion if dice loss expects it
+        if self.dice.softmax and n_pred_ch > 1:
+            input = torch.softmax(input, 1)
+
         if not self.include_background:
             if n_pred_ch == 1:
                 warnings.warn("single channel prediction, `include_background=False` ignored.")
@@ -854,8 +869,23 @@ class DiceFocalLoss(_Loss):
                 target = target[:, 1:]
                 input = input[:, 1:]
 
-        dice_loss = self.dice(input, target)
-        focal_loss = self.focal(input, target)
+        # Create a dice loss instance with softmax disabled since we already applied it
+        dice_loss = DiceLoss(
+            include_background=True,  # Already handled above
+            to_onehot_y=False,  # Already handled above
+            sigmoid=self.dice.sigmoid,
+            softmax=False,  # Already applied above
+            other_act=self.dice.other_act,
+            squared_pred=self.dice.squared_pred,
+            jaccard=self.dice.jaccard,
+            reduction=self.dice.reduction,
+            smooth_nr=self.dice.smooth_nr,
+            smooth_dr=self.dice.smooth_dr,
+            batch=self.dice.batch,
+        )
+        dice_loss = dice_loss(input, target)
+
+        focal_loss = self.focal(focal_input, focal_target)
         total_loss: torch.Tensor = self.lambda_dice * dice_loss + self.lambda_focal * focal_loss
         return total_loss
 
